cdr3_hotspot_mut_vector[i] <- str_count(flattened_string, "CDR3")
setTxtProgressBar(pb, i)
}
#Condense hotspot locations into a data frame
processed_v_region_hotspots <- tibble(sequence_id = v_region_hotspots$sequence_id,
fr1_hotspot_loci = fr1_hotspot_mut_vector,
fr2_hotspot_loci = fr2_hotspot_mut_vector,
fr3_hotspot_loci = fr3_hotspot_mut_vector,
cdr1_hotspot_loci = cdr1_hotspot_mut_vector,
cdr2_hotspot_loci = cdr2_hotspot_mut_vector,
cdr3_hotspot_loci = cdr3_hotspot_mut_vector,
total_non_junction_hotspot_loci = sum(fr1_hotspot_loci,
fr2_hotspot_loci,
fr3_hotspot_loci,
cdr1_hotspot_loci,
cdr2_hotspot_loci))
##Set working directory for individual files
setwd(individual_directory)
##Get the individual file list
file_list <- list.files(individual_directory)
##Initialize a list with an element for each sequence
sequence_list <- vector("list", length = length(file_list))
##Initialize a status bar
print("Identifying hotspot mutations")
pb <- txtProgressBar(min = 0, max = length(file_list), style = 3)
##Find the hotspot mutations for each individual sequence
for (i in 1:length(file_list)) {
#Read in the individual file
seq <- read_file(file_list[i])
#Pull the hotspot text chunk
hotspot_chunk <- gsub(".*and hotspots motifs\\\n(.*)\\\n\\\n\\\n12.*.", "\\1", seq)
#Break the chunk into individual mutations
mutation_string <- str_split(hotspot_chunk, "\n")[[1]]
# #Get rid of the aggregate V mutations
# mutation_string_vs_removed <- mutation_string[!grepl("V-REGION", mutation_string)]
#Identify mutations in hotspots
hotspot_mutations <- mutation_string[grepl("\\[", mutation_string)]
#Flatten the hotspot mutations
combined_hotspot_mutations <- str_flatten(hotspot_mutations)
#If there are no hotspot mutations, fill with zeros
if(length(combined_hotspot_mutations) == 0) {
fr1_hotspot_muts <- 0
fr2_hotspot_muts <- 0
fr3_hotspot_muts <- 0
cdr1_hotspot_muts <- 0
cdr2_hotspot_muts <- 0
cdr3_hotspot_muts <- 0
total_non_junction_hotspot_muts <- 0
#Else, count the hotspot mutation regions
} else {
fr1_hotspot_muts <- str_count(combined_hotspot_mutations, "FR1")
fr2_hotspot_muts <- str_count(combined_hotspot_mutations, "FR2")
fr3_hotspot_muts <- str_count(combined_hotspot_mutations, "FR3")
cdr1_hotspot_muts <- str_count(combined_hotspot_mutations, "CDR1")
cdr2_hotspot_muts <- str_count(combined_hotspot_mutations, "CDR2")
cdr3_hotspot_muts <- str_count(combined_hotspot_mutations, "CDR3")
total_non_junction_hotspot_muts <- sum(fr1_hotspot_muts, fr2_hotspot_muts, fr3_hotspot_muts, cdr1_hotspot_muts, cdr2_hotspot_muts)
}
#Make a tibble with all of the hotspot mutations by region
hotspot_df <- tibble(sequence_id = gsub("(.*)_[0-9]+$", "\\1", file_list[i]),
fr1_hotspot_muts, fr2_hotspot_muts, fr3_hotspot_muts, cdr1_hotspot_muts, cdr2_hotspot_muts, cdr3_hotspot_muts, total_non_junction_hotspot_muts)
#Add that tibble to the sequence list
sequence_list[[i]] <- hotspot_df
setTxtProgressBar(pb, i)
}##End, FOR loop
#Bind all of the sequences back together
hotspot_df <- bind_rows(sequence_list)
#Join hotspot locations and mutation data
processed_v_region_hotspots <- left_join(processed_v_region_hotspots, hotspot_df, by = "sequence_id")
return(processed_v_region_hotspots)
}##End, process_imgt_v_region_mutation_hotspots_files()
############################
###Global processing
############################
##Create all of the processed files using the above functions
processed_summary <- process_imgt_summary_file()
processed_nt_sequences <- process_imgt_nt_sequences_file()
processed_gapped_nt_sequences <- process_imgt_gapped_nt_sequences_file()
processed_aa_sequences <- process_imgt_aa_sequences_file()
processed_gapped_aa_sequences <- process_imgt_gapped_aa_sequences_file()
processed_nt_mutation_summary <- process_imgt_v_region_nt_mutation_statistics_file()
processed_aa_mutation_summary <- process_imgt_v_region_aa_change_statistics_file()
##Process hotspots if individual files are present
processed_hotspot_mutation_summary <- FALSE
if (imgt_individual_file_directory != FALSE) {
processed_hotspot_mutation_summary <- process_imgt_v_region_mutation_hotspots_files()
}
##Bind them together using the sequence_id
combined_tibble <- plyr::join_all(list(processed_summary,
processed_nt_sequences,
processed_gapped_nt_sequences,
processed_aa_sequences,
processed_gapped_aa_sequences,
processed_nt_mutation_summary,
processed_aa_mutation_summary),
by = "sequence_id")
if (processed_hotspot_mutation_summary != FALSE) {
combined_tibble <- left_join(combined_tibble, processed_hotspot_mutation_summary, by = "sequence_id")
}
##Add additional statistics of relavance to future study
combined_tibble <- combined_tibble %>%
mutate(fr1_nt_mut_freq = fr1_imgt_nb_of_mutations / fr1_imgt_nb_of_nucleotides * 100, ## Mutation frequencies
fr2_nt_mut_freq = fr2_imgt_nb_of_mutations / fr2_imgt_nb_of_nucleotides * 100,
fr3_nt_mut_freq = fr3_imgt_nb_of_mutations / fr3_imgt_nb_of_nucleotides * 100,
cdr1_nt_mut_freq = cdr1_imgt_nb_of_mutations / cdr1_imgt_nb_of_nucleotides * 100,
cdr2_nt_mut_freq = cdr2_imgt_nb_of_mutations / cdr2_imgt_nb_of_nucleotides * 100,
cdr3_nt_mut_freq = cdr3_imgt_nb_of_mutations / cdr3_imgt_nb_of_nucleotides * 100,
v_nt_mut_freq = v_region_nb_of_mutations / v_region_nb_of_nucleotides * 100,
fr1_nonsilent_mut_ratio = fr1_imgt_nb_of_nonsilent_mutations / fr1_imgt_nb_of_mutations, ## Nonsilent mutation ratios
fr2_nonsilent_mut_ratio = fr2_imgt_nb_of_nonsilent_mutations / fr2_imgt_nb_of_mutations,
fr3_nonsilent_mut_ratio = fr3_imgt_nb_of_nonsilent_mutations / fr3_imgt_nb_of_mutations,
cdr1_nonsilent_mut_ratio = cdr1_imgt_nb_of_nonsilent_mutations / cdr1_imgt_nb_of_mutations,
cdr2_nonsilent_mut_ratio = cdr2_imgt_nb_of_nonsilent_mutations / cdr2_imgt_nb_of_mutations,
cdr3_nonsilent_mut_ratio = cdr3_imgt_nb_of_nonsilent_mutations / cdr3_imgt_nb_of_mutations,
v_nonsilent_mut_ratio = v_region_nb_of_nonsilent_mutations / v_region_nb_of_mutations,
fr1_transitions = (fr1_imgt_a_into_g + fr1_imgt_g_into_a + fr1_imgt_c_into_t + fr1_imgt_t_into_c), ## Transition vs transversion counts
fr1_transversions = fr1_imgt_nb_of_mutations - fr1_transitions,
fr2_transitions = (fr2_imgt_a_into_g + fr2_imgt_g_into_a + fr2_imgt_c_into_t + fr2_imgt_t_into_c),
fr2_transversions = fr2_imgt_nb_of_mutations - fr2_transitions,
fr3_transitions = (fr3_imgt_a_into_g + fr3_imgt_g_into_a + fr3_imgt_c_into_t + fr3_imgt_t_into_c),
fr3_transversions = fr3_imgt_nb_of_mutations - fr3_transitions,
cdr1_transitions = (cdr1_imgt_a_into_g + cdr1_imgt_g_into_a + cdr1_imgt_c_into_t + cdr1_imgt_t_into_c),
cdr1_transversions = cdr1_imgt_nb_of_mutations - cdr1_transitions,
cdr2_transitions = (cdr2_imgt_a_into_g + cdr2_imgt_g_into_a + cdr2_imgt_c_into_t + cdr2_imgt_t_into_c),
cdr2_transversions = cdr2_imgt_nb_of_mutations - cdr2_transitions,
cdr3_transitions = (cdr3_imgt_a_into_g + cdr3_imgt_g_into_a + cdr3_imgt_c_into_t + cdr3_imgt_t_into_c),
cdr3_transversions = cdr3_imgt_nb_of_mutations - cdr3_transitions,
total_non_junction_v_transitions = fr1_transitions + fr2_transitions + fr3_transitions + cdr1_transitions + cdr2_transitions,
total_non_junction_v_transversions = fr1_transversions + fr2_transversions + fr3_transversions + cdr1_transversions + cdr2_transversions,
fr1_transition_ratio = fr1_transitions / fr1_imgt_nb_of_mutations, ## Transition ratios
fr2_transition_ratio = fr2_transitions / fr2_imgt_nb_of_mutations,
fr3_transition_ratio = fr3_transitions / fr3_imgt_nb_of_mutations,
cdr1_transition_ratio = cdr1_transitions / cdr1_imgt_nb_of_mutations,
cdr2_transition_ratio = cdr2_transitions / cdr2_imgt_nb_of_mutations,
cdr3_transition_ratio = cdr3_transitions / cdr3_imgt_nb_of_mutations,
non_junction_transition_ratio = total_non_junction_v_transitions / (fr1_imgt_nb_of_mutations + fr2_imgt_nb_of_mutations + fr3_imgt_nb_of_mutations + cdr1_imgt_nb_of_mutations + cdr2_imgt_nb_of_mutations),
fr1_aa_mut_freq = fr1_imgt_nb_of_aa_changes / fr1_imgt_nb_of_aa, ## Amino acid conversion frequency
fr2_aa_mut_freq = fr2_imgt_nb_of_aa_changes / fr2_imgt_nb_of_aa,
fr3_aa_mut_freq = fr3_imgt_nb_of_aa_changes / fr3_imgt_nb_of_aa,
cdr1_aa_mut_freq = cdr1_imgt_nb_of_aa_changes / cdr1_imgt_nb_of_aa,
cdr2_aa_mut_freq = cdr2_imgt_nb_of_aa_changes / cdr2_imgt_nb_of_aa,
cdr3_aa_mut_freq = cdr3_imgt_nb_of_aa_changes / cdr3_imgt_nb_of_aa,
v_aa_mut_freq = (v_region_nb_of_aa / v_region_nb_of_aa_changes),
contains_avy_in_fr1 = grepl("AVY", aa_fr1), ## Detects AVY in FR1
contains_qw_in_fr1 = grepl("QW", aa_fr1)) ## Detects QW in FR1
if (processed_hotspot_mutation_summary != FALSE) {
combined_tibble <- combined_tibble %>%
mutate(fr1_pct_mutations_in_hotspots = fr1_hotspot_muts / fr1_imgt_nb_of_mutations * 100,
fr2_pct_mutations_in_hotspots = fr2_hotspot_muts / fr2_imgt_nb_of_mutations * 100,
fr3_pct_mutations_in_hotspots = fr3_hotspot_muts / fr3_imgt_nb_of_mutations * 100,
cdr1_pct_mutations_in_hotspots = cdr1_hotspot_muts / cdr1_imgt_nb_of_mutations * 100,
cdr2_pct_mutations_in_hotspots = cdr2_hotspot_muts / cdr2_imgt_nb_of_mutations * 100,
cdr3_pct_mutations_in_hotspots = cdr3_hotspot_muts / cdr3_imgt_nb_of_mutations * 100,
total_non_junction_pct_mutations_in_hotspots = total_non_junction_hotspot_muts / (fr1_imgt_nb_of_mutations +
fr2_imgt_nb_of_mutations +
fr3_imgt_nb_of_mutations +
cdr1_imgt_nb_of_mutations +
cdr2_imgt_nb_of_mutations),
fr1_pct_hotspots_mutated = fr1_hotspot_muts / fr1_hotspot_loci * 100,
fr2_pct_hotspots_mutated = fr2_hotspot_muts / fr2_hotspot_loci * 100,
fr3_pct_hotspots_mutated = fr3_hotspot_muts / fr3_hotspot_loci * 100,
cdr1_pct_hotspots_mutated = cdr1_hotspot_muts / cdr1_hotspot_loci * 100,
cdr2_pct_hotspots_mutated = cdr2_hotspot_muts / cdr2_hotspot_loci * 100,
cdr3_pct_hotspots_mutated = cdr3_hotspot_muts / cdr3_hotspot_loci * 100,
total_non_junction_pct_hotspots_mutated = total_non_junction_hotspot_muts / total_non_junction_hotspot_loci * 100)
}
##Bring in processed CellRanger annotations
processed_cellranger_annotations <- read_csv(processed_cellranger_annotations_file)
#Merge in the data
merged_tibble <- left_join(processed_cellranger_annotations, combined_tibble, by = c("indexed_contig_id" = "sequence_id"))
##pull out the isotypes from the heavy chains
isotypes <- merged_tibble %>% filter(chain_type == "igh") %>% select(indexed_barcode, isotype = c_gene)
isotypes$isotype <- tolower(gsub("IGH(.*)", "\\1", isotypes$isotype))
merged_tibble <- left_join(merged_tibble, isotypes, by = "indexed_barcode")
##Arrange the tibble for ease of future processing.
if (processed_hotspot_mutation_summary != FALSE) {
merged_tibble <- merged_tibble %>%
select(indexed_contig_id:seq,
chain_type,
isotype,
reads:j_region_identity_pct,
nt_vdj:aa_gapped_j,
fr1_nt_mut_freq:contains_qw_in_fr1,
"v_region_nb_of_positions_including_imgt_gaps_(nt)":cdr3_imgt_very_dissimilar,
fr1_hotspot_loci:total_non_junction_hotspot_muts,
fr1_pct_mutations_in_hotspots:total_non_junction_pct_hotspots_mutated)
} else {
merged_tibble <- merged_tibble %>%
select(indexed_contig_id:seq,
chain_type,
isotype,
reads:j_region_identity_pct,
nt_vdj:aa_gapped_j,
fr1_nt_mut_freq:contains_qw_in_fr1,
"v_region_nb_of_positions_including_imgt_gaps_(nt)":cdr3_imgt_very_dissimilar)
}
##Return the table
superrseq_outs_path <- paste0(imgt_summary_file_directory, "/superrseq_outs/")
superrseq_seurat_outs_path <- paste0(superrseq_outs_path, "outs_for_seurat/")
superrseq_seurat_outs_mex_path <- paste0(superrseq_seurat_outs_path, "superrseq_vdj_features/")
dir.create(superrseq_outs_path)
dir.create(superrseq_seurat_outs_path)
dir.create(superrseq_seurat_outs_mex_path)
setwd(superrseq_outs_path)
write_csv(merged_tibble, paste("superrseq_processed_imgt_output.index_", merged_tibble$sample_index[1], ".csv", sep = ""))
##Create new seurat directories
dir.create(paste(imgt_summary_file_directory))
if (return_df == TRUE) {
return(merged_tibble)
} else {
print("Processing complete!")
}
}### End, process_imgt_output()
process_imgt_output("/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/single_cell_analysis/vdj_processing/imgt_outputs/index_32/summary_files",
"/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/single_cell_analysis/vdj_processing/cellranger_outputs/index_32/BM3_superrseq_processed_cellranger_outputs/filtered_singlet_annotations.index_32.csv",
"/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/single_cell_analysis/vdj_processing/imgt_outputs/index_32/individual_files",
TRUE)
temp <- read_csv("/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/single_cell_analysis/vdj_processing/imgt_outputs/index_32/summary_files/superrseq_outs/superrseq_processed_imgt_output.index_32.csv")
head(temp)
assign_lineages <- function(data, pct_homology = 0.85, return_df = FALSE) {
require(Biostrings)
require(dplyr)
require(readr)
###Identify type of data
if ("data.frame" %in% class(data)) {
data <- data
} else if (class(data) == "list"){
data <- do.call(rbind, data)
} else if (grepl("\\.csv", data)) {
## Extract the directory for the single .csv
subdirectory_path <- gsub("superrseq.*", "", data)
setwd(subdirectory_path)
data <- read_csv(data)
} else if (dir.exists(data)) {
setwd(data)
file_list <- list.files(data)
data_list <- vector("list", length = length(file_list))
for (i in 1:length(file_list)) {
data_list[[i]] <- read_csv(file_list[i])
}
data <- bind_rows(data_list)
}
### Lineage assignment function
lin_assign <- function(data) {
### Populate sequences
cdr3_seqs <- data[["cdr3_seq"]]
### Create the initial distance matrix
seq_dist_matrix <- stringDist(unique(cdr3_seqs), method = "hamming", upper = TRUE, diag = TRUE)
percent_homology_matrix <- 1 - (as.matrix(seq_dist_matrix) / nchar(cdr3_seqs)[1])
colnames(percent_homology_matrix) <- rownames(percent_homology_matrix) <- unique(cdr3_seqs)
### Create the sequence frequency table
seq_freq_table <- sort(table(cdr3_seqs), decreasing = TRUE)
### iterative assignment of lineages
while (length(seq_freq_table) >= 1) {
### identify most abundant sequence
highest_freq_seq <- names(seq_freq_table)[1]
### Isolate the row of the highest-frequency seq
seq_row <- as.vector(percent_homology_matrix[highest_freq_seq,,drop = FALSE])
names(seq_row) <- colnames(percent_homology_matrix[highest_freq_seq,,drop = FALSE])
### Identify sequences within homology threshold
homology_names <- names(which(seq_row >= pct_homology))
### Find homologous sequences in the data
lineage_index <- which(data[["cdr3_seq"]] %in% homology_names)
### Assign lineage_id with the lineage id counter
data$lineage_id[lineage_index] <- lineage_counter
### Prepare indexes for sequence removal from the table and matrix
table_index <- which(names(seq_freq_table) %in% homology_names)
matrix_index <- which(colnames(percent_homology_matrix) %in% homology_names)
### Remove those sequences from the table and matrix
seq_freq_table <- seq_freq_table[-table_index]
percent_homology_matrix <- percent_homology_matrix[-matrix_index,-matrix_index, drop = FALSE]
### Click over the lineage assignment counter
lineage_counter <<- lineage_counter + 1
} ### End "while" loop
return(data)
} ### End lin_assign function
### Make a trimmed data frame for processing (removing light chains)
trimmed_data <- data %>%
filter(chain_type == "igh") %>%
dplyr::select(indexed_barcode, v_gene, j_gene, cdr3_seq = nt_cdr3, cdr3_len = nt_cdr3_length)
### Extract CDR3 length, and add a placeholder for lineage id
trimmed_data <- trimmed_data %>%
mutate(lineage_id = rep(NA))
### Split the list on V, J, and CDR3 length
split_list <- split(trimmed_data, list(factor(trimmed_data[["v_gene"]]), factor(trimmed_data[["j_gene"]]), factor(trimmed_data[["cdr3_len"]])), drop = TRUE)
### Initialize lineage counter
lineage_counter <- 1
### Assignment visualizer
for (i in seq_along(split_list)) {
if (i %% 100 == 0) {
print(paste(i, "out of", length(split_list), "v/j/cdr3 length families assigned"))
}
### assign the lineages
split_list[[i]] <- lin_assign(split_list[[i]])
}
### collapse the list
assigned_lins <- bind_rows(split_list)
### assign the new lineage ids
assigned_lins <- assigned_lins %>% select(indexed_barcode, lineage_id)
### join the new lineage ids to the data
data <- left_join(data, assigned_lins, by = "indexed_barcode")
### Add in pat_lins when available
if ("patient_id" %in% names(data)) {
data$pat_lin <- paste(data$patient_id, data$lineage_id, sep = "_")
}
### Create an index .txt file
split_index_list <- split(data, factor(data$sample_index))
index_reference_key <- vector("list", length = length(split_index_list))
split_lineage_list <- vector("list", length = length(split_index_list))
names(split_lineage_list) <- unique(data$sample_index)
start_metadata <- which(names(split_index_list[[1]]) == "sample_index")
end_metadata <- which(names(split_index_list[[1]]) == "seq") - 1
for (i in 1:length(split_index_list)) {
index_reference_key[[i]] <- split_index_list[[i]][1,] %>% select(start_metadata:end_metadata)
split_lineage_list[[i]] <- unique(split_index_list[[i]]$lineage_id)
data[[paste("lineage_in_index_", names(split_lineage_list)[i], sep = "")]] <- FALSE
}
indices <- unique(data$sample_index)
for (i in 1:nrow(data)) {
for (j in 1:length(indices)) {
if (data[i,"lineage_id"] %in% split_lineage_list[[j]]) {
data[i,paste("lineage_in_index_", names(split_lineage_list)[j], sep = "")] <- TRUE
}
}
}
index_reference_key <- bind_rows(index_reference_key)
write_csv(index_reference_key, "index_reference_key.csv")
write_csv(data, "lineage_processed_data.csv")
### return the data
if (return_df == TRUE) {
return(data)
} else {
print("Processing complete!")
}
}
assign_lineages("/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/single_cell_analysis/vdj_processing/imgt_outputs/index_32/summary_files/superrseq_outs/superrseq_processed_imgt_output.index_32.csv")
rm(list = ls())
extract_mutation_data <- function(imgt_individual_file_directory) {
##Set working directory for individual files
setwd(individual_directory)
##Get the individual file list
file_list <- list.files(individual_directory)
##Initialize a list with an element for each sequence
sequence_list <- vector("list", length = length(file_list))
##Initialize a status bar
print("Identifying hotspot mutations")
pb <- txtProgressBar(min = 0, max = length(file_list), style = 3)
##Find the hotspot mutations for each individual sequence
for (i in 1:length(file_list)) {
#Read in the individual file
seq <- read_file(file_list[i])
return(seq)
#Pull the hotspot text chunk
hotspot_chunk <- gsub(".*and hotspots motifs\\\n(.*)\\\n\\\n\\\n12.*.", "\\1", seq)
#Break the chunk into individual mutations
mutation_string <- str_split(hotspot_chunk, "\n")[[1]]
# #Get rid of the aggregate V mutations
# mutation_string_vs_removed <- mutation_string[!grepl("V-REGION", mutation_string)]
#Identify mutations in hotspots
hotspot_mutations <- mutation_string[grepl("\\[", mutation_string)]
#Flatten the hotspot mutations
combined_hotspot_mutations <- str_flatten(hotspot_mutations)
}
}
temp <- extract_mutation_data("/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/totalseq_repository/test_data/imgt_vdj_outs/individual_files")
extract_mutation_data <- function(imgt_individual_file_directory) {
##Set working directory for individual files
setwd(imgt_individual_file_directory)
##Get the individual file list
file_list <- list.files(imgt_individual_file_directory)
##Initialize a list with an element for each sequence
sequence_list <- vector("list", length = length(file_list))
##Initialize a status bar
print("Identifying hotspot mutations")
pb <- txtProgressBar(min = 0, max = length(file_list), style = 3)
##Find the hotspot mutations for each individual sequence
for (i in 1:length(file_list)) {
#Read in the individual file
seq <- read_file(file_list[i])
return(seq)
#Pull the hotspot text chunk
hotspot_chunk <- gsub(".*and hotspots motifs\\\n(.*)\\\n\\\n\\\n12.*.", "\\1", seq)
#Break the chunk into individual mutations
mutation_string <- str_split(hotspot_chunk, "\n")[[1]]
# #Get rid of the aggregate V mutations
# mutation_string_vs_removed <- mutation_string[!grepl("V-REGION", mutation_string)]
#Identify mutations in hotspots
hotspot_mutations <- mutation_string[grepl("\\[", mutation_string)]
#Flatten the hotspot mutations
combined_hotspot_mutations <- str_flatten(hotspot_mutations)
}
}
temp <- extract_mutation_data("/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/totalseq_repository/test_data/imgt_vdj_outs/individual_files")
temp
extract_mutation_data <- function(imgt_individual_file_directory) {
##Set working directory for individual files
setwd(imgt_individual_file_directory)
##Get the individual file list
file_list <- list.files(imgt_individual_file_directory)
##Initialize a list with an element for each sequence
sequence_list <- vector("list", length = length(file_list))
##Initialize a status bar
print("Identifying hotspot mutations")
pb <- txtProgressBar(min = 0, max = length(file_list), style = 3)
##Find the hotspot mutations for each individual sequence
for (i in 1:length(file_list)) {
#Read in the individual file
seq <- read_file(file_list[i])
#Pull the hotspot text chunk
hotspot_chunk <- gsub(".*and hotspots motifs\\\n(.*)\\\n\\\n\\\n12.*.", "\\1", seq)
#Break the chunk into individual mutations
mutation_string <- str_split(hotspot_chunk, "\n")[[1]]
return(mutation_string)
# #Get rid of the aggregate V mutations
# mutation_string_vs_removed <- mutation_string[!grepl("V-REGION", mutation_string)]
#Identify mutations in hotspots
hotspot_mutations <- mutation_string[grepl("\\[", mutation_string)]
#Flatten the hotspot mutations
combined_hotspot_mutations <- str_flatten(hotspot_mutations)
}
}
temp <- extract_mutation_data("/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/totalseq_repository/test_data/imgt_vdj_outs/individual_files")
head(temp)
length(temp)
extract_mutation_data <- function(imgt_individual_file_directory) {
##Set working directory for individual files
setwd(imgt_individual_file_directory)
##Get the individual file list
file_list <- list.files(imgt_individual_file_directory)
return(file_list)
##Initialize a list with an element for each sequence
sequence_list <- vector("list", length = length(file_list))
##Initialize a status bar
print("Identifying hotspot mutations")
pb <- txtProgressBar(min = 0, max = length(file_list), style = 3)
##Find the hotspot mutations for each individual sequence
for (i in 1:length(file_list)) {
#Read in the individual file
seq <- read_file(file_list[i])
#Pull the hotspot text chunk
hotspot_chunk <- gsub(".*and hotspots motifs\\\n(.*)\\\n\\\n\\\n12.*.", "\\1", seq)
#Break the chunk into individual mutations
mutation_string <- str_split(hotspot_chunk, "\n")[[1]]
mutation_df <- tibble(indexed_contig_id = )
for (j in 1:length(mutation_string)) {
}
hotspot_mutations <- mutation_string[grepl("\\[", mutation_string)]
#Flatten the hotspot mutations
combined_hotspot_mutations <- str_flatten(hotspot_mutations)
}
}
temp <- extract_mutation_data("/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/totalseq_repository/test_data/imgt_vdj_outs/individual_files")
str(temp)
extract_mutation_data <- function(imgt_individual_file_directory) {
##Set working directory for individual files
setwd(imgt_individual_file_directory)
##Get the individual file list
file_list <- list.files(imgt_individual_file_directory)
##Initialize a list with an element for each sequence
sequence_list <- vector("list", length = length(file_list))
##Initialize a status bar
print("Identifying hotspot mutations")
pb <- txtProgressBar(min = 0, max = length(file_list), style = 3)
##Find the hotspot mutations for each individual sequence
for (i in 1:length(file_list)) {
#Read in the individual file
seq <- read_file(file_list[i])
#Pull the hotspot text chunk
hotspot_chunk <- gsub(".*and hotspots motifs\\\n(.*)\\\n\\\n\\\n12.*.", "\\1", seq)
#Break the chunk into individual mutations
mutation_string <- str_split(hotspot_chunk, "\n")[[1]]
mutation_df <- tibble(indexed_contig_id = rep(file_list[i], length(file_list)))
return(mutation_df)
for (j in 1:length(mutation_string)) {
}
hotspot_mutations <- mutation_string[grepl("\\[", mutation_string)]
#Flatten the hotspot mutations
combined_hotspot_mutations <- str_flatten(hotspot_mutations)
}
}
temp <- extract_mutation_data("/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/totalseq_repository/test_data/imgt_vdj_outs/individual_files")
> str(temp)
extract_mutation_data <- function(imgt_individual_file_directory) {
##Set working directory for individual files
setwd(imgt_individual_file_directory)
##Get the individual file list
file_list <- list.files(imgt_individual_file_directory)
##Initialize a list with an element for each sequence
sequence_list <- vector("list", length = length(file_list))
##Initialize a status bar
print("Identifying hotspot mutations")
pb <- txtProgressBar(min = 0, max = length(file_list), style = 3)
##Find the hotspot mutations for each individual sequence
for (i in 1:length(file_list)) {
#Read in the individual file
seq <- read_file(file_list[i])
#Pull the hotspot text chunk
hotspot_chunk <- gsub(".*and hotspots motifs\\\n(.*)\\\n\\\n\\\n12.*.", "\\1", seq)
#Break the chunk into individual mutations
mutation_string <- str_split(hotspot_chunk, "\n")[[1]]
mutation_df <- tibble("indexed_contig_id" = c(rep(file_list[i], length(file_list))))
return(mutation_df)
for (j in 1:length(mutation_string)) {
}
hotspot_mutations <- mutation_string[grepl("\\[", mutation_string)]
#Flatten the hotspot mutations
combined_hotspot_mutations <- str_flatten(hotspot_mutations)
}
}
temp <- extract_mutation_data("/Users/matt/Desktop/Sanz Lab Projects/Ghosn Collaboration/TotalSeq/totalseq_repository/test_data/imgt_vdj_outs/individual_files")
> str(temp)
?rep
